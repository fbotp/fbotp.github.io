<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>C语言准备就绪！</title>
    <url>/2020/06/10/C%E8%AF%AD%E8%A8%80%E5%87%86%E5%A4%87%E5%B0%B1%E7%BB%AA%EF%BC%81/</url>
    <content><![CDATA[<p>Code::Block再度回归，要开始难过的数据结构了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include&lt;stdio.h&gt;</span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">	printf(&quot;破釜沉舟，终能取胜！\n&quot;);</span><br><span class="line">	printf(&quot;0 error(s), 0 warning(s)\n&quot;);</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<p>突然意识到了问题,Python害人不浅啊QAQ，现在写代码完全没有写分号的想法……</p>
]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title>Freenom域名注册</title>
    <url>/2020/06/23/Freenom%E5%9F%9F%E5%90%8D%E6%B3%A8%E5%86%8C/</url>
    <content><![CDATA[<p>使用firefox/google chrome下载gooreplacer插件，将<code>www.google.com/recaptcha</code>替换为<code>recaptcha.net/recaptcha</code>，无需翻墙即可进行域名购买。</p>
]]></content>
      <categories>
        <category>Website</category>
      </categories>
      <tags>
        <tag>Freenom</tag>
        <tag>Firefox</tag>
        <tag>Domain</tag>
        <tag>Chrome</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian配置分辨率和字体大小</title>
    <url>/2020/06/13/Debian%E9%85%8D%E7%BD%AE%E5%88%86%E8%BE%A8%E7%8E%87%E5%92%8C%E5%AD%97%E4%BD%93%E5%A4%A7%E5%B0%8F/</url>
    <content><![CDATA[<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vi &#x2F;etc&#x2F;default&#x2F;grub</span><br></pre></td></tr></table></figure>
<p>修改为<code>GRUB_CMDLINE_LINUX=&quot;vga=0x31B&quot;</code>，<code>GRUB_GFXMODE=1280x1024</code>。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo update-grub</span><br><span class="line">sudo reboot</span><br></pre></td></tr></table></figure>
<p>分辨率修改成功。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo dpkg-reconfigure console-setup</span><br></pre></td></tr></table></figure>
<p>按回车到<code>Font for the console</code>界面，挑一个合适的。</p>
]]></content>
      <categories>
        <category>System</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>人生中第一个成功的私活</title>
    <url>/2020/06/24/%E4%BA%BA%E7%94%9F%E4%B8%AD%E7%AC%AC%E4%B8%80%E4%B8%AA%E6%88%90%E5%8A%9F%E7%9A%84%E7%A7%81%E6%B4%BB/</url>
    <content><![CDATA[<p>第一个私活，两个送分题一个10块，希望还有这种好事。</p>
]]></content>
      <categories>
        <category>Daily</category>
      </categories>
      <tags>
        <tag>Money</tag>
      </tags>
  </entry>
  <entry>
    <title>永远失去了猪窝</title>
    <url>/2020/06/07/%E6%B0%B8%E8%BF%9C%E5%A4%B1%E5%8E%BB%E4%BA%86%E7%8C%AA%E7%AA%9D/</url>
    <content><![CDATA[<p>想了那么久怎么关了这个网站，还悄悄写了日记想让贝贝看见，结果到最后也看不到那篇了。总是这么突然，猝不及防。以前说，想贝贝的时候，可以看看截屏的日记，现在真的只剩下看日记了。<br>太残忍了。</p>
]]></content>
      <categories>
        <category>NOTICE</category>
      </categories>
      <tags>
        <tag>猪窝</tag>
      </tags>
  </entry>
  <entry>
    <title>WSL备份还原及设置默认用户</title>
    <url>/2020/06/15/WSL%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F%E5%8F%8A%E8%AE%BE%E7%BD%AE%E9%BB%98%E8%AE%A4%E7%94%A8%E6%88%B7/</url>
    <content><![CDATA[<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wsl --export debian debian.tar</span><br><span class="line">wsl --unregister debian</span><br><span class="line">wsl --import debian C:\Users\小贝贝\AppData\Local\Packages\TheDebianProject.DebianGNULinux_76v4gfsz19hv4\LocalState debian.tar</span><br><span class="line">debian config --default-user zero</span><br></pre></td></tr></table></figure>
<p>一气呵成</p>
]]></content>
      <categories>
        <category>System</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>WSL</tag>
      </tags>
  </entry>
  <entry>
    <title>猪窝从Frp换为Ngrok</title>
    <url>/2020/06/04/%E7%8C%AA%E7%AA%9D%E4%BB%8EFrp%E6%8D%A2%E4%B8%BANgrok/</url>
    <content><![CDATA[<p>终于，Frp不堪重负，已经没有当时那么快的速度了。国人撸起羊毛来太狠了，公益服务器都顶不住了。<br>我恨小学生，也恨图小便宜不管自己用不用的人。<br>Ngrok目前速度还能接受，希望不要有更多的白嫖怪了，给真正需要的人一点空间吧。<a href="https://oursecretbase.top" target="_blank" rel="noopener">猪窝</a>换为了以前就找到的Ngrok免费服务器，希望它还能坚持下去。毕竟，如果再有类似的大实验，全靠它撑着呢。<br>看着猪窝每况愈下，总有一种看着长大的孩子突然要离开自己的感觉。<br><em>你知道你留不住它了，但是你还是在努力。你想守住的不是别的什么，只是当时那个特别的自己。</em></p>
]]></content>
      <categories>
        <category>NOTICE</category>
      </categories>
      <tags>
        <tag>猪窝</tag>
        <tag>Frp</tag>
        <tag>Ngrok</tag>
      </tags>
  </entry>
  <entry>
    <title>论Python有多慢</title>
    <url>/2020/06/08/%E8%AE%BAPython%E6%9C%89%E5%A4%9A%E6%85%A2/</url>
    <content><![CDATA[<p>Python简单归简单，实在是太太太太耗内存了，数据一大就不行了。以后做大数据的时候，还是能用Java/Spark就用吧，速度是硬伤，不会还是要好好学。:(<br>在Linux终端下使用matplotlib，数据一大，运行就越来越慢慢慢慢慢，忍不了了，果然没有好馅饼，简单是简单，慢更慢了，和IDLE有的一拼。<br>论什么时候才会放弃Python迎接Java/Spark。</p>
<hr>
<p>是我憨憨了，根据网上大神的说法，尽量减少plt.scatter/plot之类的这种函数的调用，就不会出那样的问题，学的还是太少了。</p>
]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>matplotlib</tag>
        <tag>idle</tag>
      </tags>
  </entry>
  <entry>
    <title>Zeroing</title>
    <url>/2020/06/04/Zeroing/</url>
    <content><![CDATA[<p><a href="https://zeroing.tk">ZI</a>，从0开始的网站。<br><em>No sweat, no sweet.</em>   </p>
]]></content>
      <categories>
        <category>NOTICE</category>
      </categories>
  </entry>
  <entry>
    <title>Techwalker聚类</title>
    <url>/2020/06/11/Techwalker%E8%81%9A%E7%B1%BB/</url>
    <content><![CDATA[<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ul>
<li>Python 3.8.2<ul>
<li>Scrapy 2.1.0</li>
<li>scrapy-redis 0.6.8</li>
<li>happybase 1.2.0</li>
<li>pyecharts 1.8.1</li>
<li>sklearn</li>
</ul>
</li>
<li>Hadoop 2.7.7</li>
<li>Hbase 1.4.9</li>
<li>redis 6.0.4 64 bit</li>
</ul>
<hr>
<h2 id="创建爬虫工程"><a href="#创建爬虫工程" class="headerlink" title="创建爬虫工程"></a>创建爬虫工程</h2><p>爬取网站：<a href="http://www.techwalker.com/files/list-7-1-0-0-1.htm" target="_blank" rel="noopener">科技行者</a><br>页面内容如下：<img src="/img/tech_web.png" alt="">根据页面内容，开始创建爬虫</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scrapy startproject myspider</span><br><span class="line">cd myspider</span><br><span class="line">scrapy genspider tech http:&#x2F;&#x2F;www.techwalker.com</span><br></pre></td></tr></table></figure>
<p>对爬虫文件进行修改</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vi myspider/item.py</span><br><span class="line"></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define here the models for your scraped items</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># https://docs.scrapy.org/en/latest/topics/items.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyspiderItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    title = scrapy.Field() <span class="comment"># 文章名称</span></span><br><span class="line">    tags = scrapy.Field() <span class="comment"># 文章标签</span></span><br><span class="line">    abstract = scrapy.Field() <span class="comment"># 文章摘要</span></span><br></pre></td></tr></table></figure>
<p>修改爬虫文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vi myspider/tech/py</span><br><span class="line"></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> myspider.items <span class="keyword">import</span> MyspiderItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TechSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'tech'</span></span><br><span class="line">    start_urls = [<span class="string">'http://www.techwalker.com/files/list-7-1-0-0-1.htm'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span> <span class="comment"># 对所有符合要求的网页进行爬取</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,int(response.xpath(<span class="string">'//*[@id="to1"]/div/div[21]/div[1]/a[10]/text()'</span>).get())+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(<span class="string">'http://www.techwalker.com/list-7-1-0-0-'</span>+str(i)+<span class="string">'-0.htm'</span>, callback=self.parse_page)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_page</span><span class="params">(self, response)</span>:</span> <span class="comment"># 对每一页上的数据进行爬取</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> response.xpath(<span class="string">'//*[@id="to1"]/div/div/div[3]'</span>):</span><br><span class="line">            item = MyspiderItem()</span><br><span class="line">            item[<span class="string">'title'</span>] = i.xpath(<span class="string">'./h2/a/text()'</span>).get()</span><br><span class="line">            item[<span class="string">'abstract'</span>] = i.xpath(<span class="string">'./p/text()'</span>).get()</span><br><span class="line">            item[<span class="string">'tags'</span>] = <span class="string">'#'</span>.join(i.xpath(<span class="string">'./div//text()'</span>).extract()).replace(<span class="string">' '</span>, <span class="string">''</span>)</span><br><span class="line">            <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>
<p>修改pipeline.py，将爬取的item写入hbase</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vi myspider/pipelines.py</span><br><span class="line"></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> .items <span class="keyword">import</span> MyspiderItem</span><br><span class="line"><span class="keyword">import</span> happybase</span><br><span class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> md5</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.project <span class="keyword">import</span> get_project_settings</span><br><span class="line">settings=get_project_settings()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyspiderPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        host = settings[<span class="string">'HBASE_HOST'</span>]</span><br><span class="line">        table_name = settings[<span class="string">'HBASE_TABLE'</span>]</span><br><span class="line">        connection = happybase.Connection(host)</span><br><span class="line">        <span class="keyword">if</span> table_name.encode(<span class="string">'utf-8'</span>) <span class="keyword">not</span> <span class="keyword">in</span> connection.tables():</span><br><span class="line">            connection.create_table(table_name,&#123;<span class="string">'essay'</span>:&#123;&#125;&#125;)</span><br><span class="line">        table = connection.table(table_name)</span><br><span class="line">        self.table = table</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(item, MyspiderItem):</span><br><span class="line">            self.table.put(md5(item[<span class="string">'title'</span>].encode(<span class="string">'utf-8'</span>)).hexdigest(), dict(((<span class="string">'essay:'</span>+k).encode(<span class="string">'utf-8'</span>),v.encode(<span class="string">'utf-8'</span>))<span class="keyword">for</span> (k,v) <span class="keyword">in</span> item.items()))</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<p>给scrapy添加redis组件，并启用pipeline</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vi myspider/setting.py</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加如下内容</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用redis替换scrapy组件</span></span><br><span class="line">SCHEDULER=<span class="string">'scrapy_redis.scheduler.Scheduler'</span></span><br><span class="line">DUPEFILTER_CLASS=<span class="string">'scrapy_redis.dupefilter.RFPDupeFilter'</span></span><br><span class="line"><span class="comment"># 使用master主机上的redis-server</span></span><br><span class="line">REDIST_HOST=<span class="string">'master'</span></span><br><span class="line">REDIST_PORT=<span class="number">6379</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据写入master主机上的Hbase的tech表中</span></span><br><span class="line">HBASE_HOST=<span class="string">'master'</span></span><br><span class="line">HBASE_TABLE=<span class="string">'tech'</span></span><br><span class="line">REDIS_URL=<span class="string">'redis://master:6379'</span></span><br><span class="line"><span class="comment"># 启用pipiline</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">'myspider.pipelines.MyspiderPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>开始爬取数据</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 开启相关服务</span><br><span class="line">start-dfs.sh &amp;&amp; start-hbase.sh &amp;&amp; hbase-daemon.sh start thrift &amp;&amp; redis-server</span><br><span class="line"># 数据获取</span><br><span class="line">scrapy crawl tech</span><br></pre></td></tr></table></figure>
<p>待执行完毕后，使用<code>hbase shell</code>命令进入hbase命令行查看数据获取情况，如下图：<img src="/img/tech_hbase.png" alt="">至此，数据获取完毕，接下来进行聚类及可视化展示。</p>
<hr>
<h2 id="进行聚类并保存聚类结果"><a href="#进行聚类并保存聚类结果" class="headerlink" title="进行聚类并保存聚类结果"></a>进行聚类并保存聚类结果</h2><p>使用爬取数据中的<code>tags</code>作为计算两篇文章之间距离的依据，使用difflib计算两篇文章的相似性，用Kmeans进行聚类，从hbase中读取数据，并将聚类结果保存到本地的<em>result.txt</em>中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> happybase</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> k_means_</span><br><span class="line"><span class="keyword">import</span> difflib</span><br><span class="line"></span><br><span class="line">num_clusters = <span class="number">50</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算两篇文章标签的近似程度</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_equal_rate</span><span class="params">(str1, str2)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>-difflib.SequenceMatcher(<span class="literal">None</span>, str1, str2).quick_ratio()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'connecting table...'</span>)</span><br><span class="line">connection = happybase.Connection(<span class="string">'master'</span>)</span><br><span class="line">table = connection.table(<span class="string">'tech'</span>)</span><br><span class="line">rawdata = [i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> table.scan()]</span><br><span class="line">connection.close()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'getting data...'</span>)</span><br><span class="line">data = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> rawdata:</span><br><span class="line">    data.append([])</span><br><span class="line">    data[<span class="number">-1</span>] = [i[v].decode(<span class="string">'utf-8'</span>) <span class="keyword">for</span> v <span class="keyword">in</span> [<span class="string">b'essay:abstract'</span>, <span class="string">b'essay:tags'</span>, <span class="string">b'essay:title'</span>]] <span class="comment"># 确保数据以[摘要， 标签， 标题]的形式读入</span></span><br><span class="line">result = &#123;&#125;</span><br><span class="line"></span><br><span class="line">print(<span class="string">'get'</span>, len(data), <span class="string">'data, clusting...'</span>)</span><br><span class="line">count_vec=CountVectorizer()</span><br><span class="line">km_matrix= count_vec.fit_transform([i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> data])</span><br><span class="line">k_means_.euclidean_distances = get_equal_rate <span class="comment"># 修改k_means的距离判断标准</span></span><br><span class="line">km = k_means_.KMeans(n_clusters=num_clusters)</span><br><span class="line">km.fit(km_matrix)</span><br><span class="line">labels = km.labels_.tolist()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">    <span class="keyword">if</span> int(labels[i]) <span class="keyword">not</span> <span class="keyword">in</span> result.keys():</span><br><span class="line">        result[int(labels[i])] = []</span><br><span class="line">    result[int(labels[i])].append(data[i])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将结果存入文件，以'@@'作为分割标志</span></span><br><span class="line">print(<span class="string">'inputing file...'</span>)</span><br><span class="line">file = open(<span class="string">'result.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> result.keys():</span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> result[k]:</span><br><span class="line">        file.write(str(k)+<span class="string">'@@'</span>+<span class="string">'\t'</span>.join(v).replace(<span class="string">'\r\n'</span>, <span class="string">''</span>).replace(<span class="string">'\n'</span>, <span class="string">''</span>)+<span class="string">'\n'</span>)</span><br><span class="line">file.close()</span><br><span class="line">print(<span class="string">'finish'</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="对聚类结果进行可视化展示"><a href="#对聚类结果进行可视化展示" class="headerlink" title="对聚类结果进行可视化展示"></a>对聚类结果进行可视化展示</h2><p>使用pyecharts库绘画</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Scatter</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> pyecharts.commons.utils <span class="keyword">import</span> JsCode</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置x轴范围，在下面的画图过程中进行调试，以防由于x轴展示不全而导致数据丢失</span></span><br><span class="line">min_x = <span class="number">10000</span></span><br><span class="line">max_x = <span class="number">-10000</span></span><br><span class="line">setting = opts.InitOpts(width=<span class="string">'1200px'</span>, height=<span class="string">'750px'</span>, page_title=<span class="string">'techwalker聚类'</span>)</span><br><span class="line">scatter = Scatter(setting)</span><br><span class="line"><span class="comment"># 隐藏标签、x轴、y轴</span></span><br><span class="line">scatter.set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">"聚类结果"</span>),</span><br><span class="line">                        xaxis_opts=opts.AxisOpts(is_show=<span class="literal">False</span>),</span><br><span class="line">                        yaxis_opts=opts.AxisOpts(is_show=<span class="literal">False</span>, ),</span><br><span class="line">                        legend_opts=opts.LegendOpts(is_show=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机生成圆形，用以表示聚类结果</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_circle</span><span class="params">(num, radius, centerx, centery, v, k)</span>:</span></span><br><span class="line">	<span class="keyword">global</span> min_x, max_x</span><br><span class="line">    points_x, points_y = [], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            x = random.randint(-radius, radius)</span><br><span class="line">            y = random.randint(-radius, radius)</span><br><span class="line">            <span class="comment"># 如果(x, y)在以(centerx, centery)为圆心、radius为半径的园内，则进行绘画</span></span><br><span class="line">            <span class="keyword">if</span> (x ** <span class="number">2</span>) + (y ** <span class="number">2</span>) &lt;= (radius ** <span class="number">2</span>):</span><br><span class="line">                points_x.append(centerx + x)</span><br><span class="line">                <span class="keyword">if</span> centerx + x &lt; min_x:</span><br><span class="line">                    min_x = centerx + x</span><br><span class="line">                <span class="keyword">if</span> centerx + x &gt; max_x:</span><br><span class="line">                    max_x = centerx + x</span><br><span class="line">                points_y.append([centery + y, <span class="string">'title:'</span>+v[i][<span class="number">2</span>], <span class="string">'tags:'</span>+v[i][<span class="number">1</span>], <span class="string">'abstract:'</span>+re.sub(<span class="string">r"(.&#123;"</span>+str(max(len(<span class="string">'title:'</span>+v[i][<span class="number">2</span>]), len(<span class="string">'tags:'</span>+v[i][<span class="number">1</span>])))+<span class="string">"&#125;)"</span>,<span class="string">"\\1&lt;br/&gt;"</span>, v[i][<span class="number">0</span>])])</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">del</span> x, y</span><br><span class="line">    scatter.add_xaxis(points_x)</span><br><span class="line">    <span class="comment"># 配置tooltips使其展示该点数据</span></span><br><span class="line">    scatter.add_yaxis(k, points_y, symbol_size=<span class="number">4.5</span>, label_opts=opts.LabelOpts(is_show=<span class="literal">False</span>), symbol_rotate=<span class="number">90</span>, tooltip_opts=opts.TooltipOpts(formatter=JsCode(<span class="string">"function(params) &#123;return params.value[2]+'&lt;br/&gt;'+params.value[3]+'&lt;br/&gt;'+params.value[4];&#125;"</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">'loading data...'</span>)</span><br><span class="line">result = &#123;&#125;</span><br><span class="line">file = open(<span class="string">'result.txt'</span>, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> file.readlines():</span><br><span class="line">    temp = i.split(<span class="string">'@@'</span>)</span><br><span class="line">    <span class="keyword">if</span> int(temp[<span class="number">0</span>]) <span class="keyword">not</span> <span class="keyword">in</span> result.keys():</span><br><span class="line">        result[int(temp[<span class="number">0</span>])] = []</span><br><span class="line">    result[int(temp[<span class="number">0</span>])].append(temp[<span class="number">1</span>][:<span class="number">-1</span>].split(<span class="string">'\t'</span>))</span><br><span class="line">file.close()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'total'</span>, len(result), <span class="string">'cluster(s), painting...'</span>)</span><br><span class="line"><span class="comment"># 给定初始圆心(30, 30)</span></span><br><span class="line">position = [<span class="number">30</span>, <span class="number">30</span>]</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> result:</span><br><span class="line">    print(<span class="string">'painting cluster'</span>, k, <span class="string">'...'</span>)</span><br><span class="line">    draw_circle(len(result[k]), math.floor(math.pow(len(result[k])/math.pi, <span class="number">0.5</span>)), position[<span class="number">0</span>], position[<span class="number">1</span>], result[k], k)</span><br><span class="line">    position[<span class="number">0</span>] += random.randint(<span class="number">-30</span>, <span class="number">30</span>)</span><br><span class="line">    position[<span class="number">1</span>] += random.randint(<span class="number">-30</span>, <span class="number">30</span>)</span><br><span class="line">scatter.set_global_opts(xaxis_opts=opts.AxisOpts(min_=min_x, max_=max_x, is_show=<span class="literal">False</span>, axislabel_opts=opts.LabelOpts(rotate=<span class="number">90</span>, interval=<span class="number">0</span>)),)</span><br><span class="line">scatter.render(<span class="string">'result.html'</span>) <span class="comment"># 将结果保存到result.html</span></span><br></pre></td></tr></table></figure>
<p>最终结果：<img src="/img/tech_result.png" alt=""></p>
]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>课设</tag>
      </tags>
  </entry>
</search>
